import grpc
import torch
import bittensor

from fastapi import APIRouter
from typing import Union, Callable
from abc import abstractmethod


class TextToEmbeddingForward( bittensor.SynapseCall ):
    name: str = "text_to_embedding_forward"
    is_forward: bool = True
    embeddings: torch.Tensor = None

    def __init__( 
            self, 
            synapse: "TextToEmbeddingSynapse", 
            request_proto: bittensor.proto.ForwardTextToEmbeddingRequest,
            forward_callback: Callable,
        ):
        super().__init__( synapse = synapse, request_proto = request_proto )
        self.text = request_proto.text
        self.forward_callback = forward_callback

    def apply( self ):
        bittensor.logging.trace( "TextToEmbeddingForward.apply()" )
        self.embeddings = self.forward_callback( text = self.text )
        bittensor.logging.trace( "TextToEmbeddingForward.apply() = len(response)", self.embeddings.shape )

    def get_response_proto( self ) -> bittensor.proto.ForwardTextToEmbeddingResponse: 
        bittensor.logging.trace( "TextToEmbeddingForward.get_response_proto()" )
        return bittensor.proto.ForwardTextToEmbeddingResponse( embeddings = self.embeddings.tolist() )
    
    def get_inputs_shape(self) -> Union[torch.Size, None]: 
        bittensor.logging.trace( "TextToEmbeddingForward.get_inputs_shape()" )
        return torch.Size( [ len(self.text) ] )
    
    def get_outputs_shape(self) -> Union[torch.Size, None]: 
        bittensor.logging.trace( "TextToEmbeddingForward.get_outputs_shape()" )
        return self.embeddings.shape

# TODO: Generate protos! TextToEmbeddingServicerm TextToEmbeddingServicer_to_server, 
# TODO: create servicer for text_to_embedding
class TextToEmbeddingSynapse( bittensor.Synapse, bittensor.grpc.TextToEmbeddingServicer ):
    name: str = "text_to_embedding"

    def attach( self, axon: 'bittensor.axon.Axon' ):
        # TODO: implement TextToEmbeddingServicer_to_server( self, server: grpc.Server) [ autogenerated with proto? ]
        bittensor.grpc.add_TextToEmbeddingServicer_to_server( self, self.axon.server )
        self.router = APIRouter()
        self.router.add_api_route("/TextToEmbedding/Forward/", self.fast_api_forward_text_to_embedding, methods=["GET"])
        self.axon.fastapi_app.include_router( self.router )
        
    @abstractmethod
    def forward( self, text: str ) -> torch.Tensor: 
        ...

    def fast_api_forward_text_to_embedding( self, hotkey: str, timeout: int, text: str ) -> torch.Tensor:
        request_proto = bittensor.proto.ForwardTextToEmbeddingRequest( 
            hotkey = hotkey, 
            version = bittensor.__version_as_int__,
            timeout = timeout, 
            text = text
        )
        call = TextToEmbeddingForward( self, request_proto, self.forward )
        bittensor.logging.trace( 'FastAPITextToEmbeddingForward: {} '.format( call ) )
        response_proto = self.apply( call = call )
        return response_proto.image

    def Forward( self, request: bittensor.proto.ForwardTextToImageRequest, context: grpc.ServicerContext ) -> bittensor.proto.ForwardTextToImageResponse:
        call = TextToEmbeddingForward( self, request, self.forward )
        bittensor.logging.trace( 'GRPCAPITextToEmbeddingForward: {} '.format( call ) )
        return self.apply( call = call ) 

